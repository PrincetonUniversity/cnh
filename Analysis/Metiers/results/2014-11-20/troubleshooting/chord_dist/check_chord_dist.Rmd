---
title: "check chord distance"
author: "Emma Fuller"
date: "November 20, 2014"
output: pdf_document
---

The previous run of infomap returned only 1 cluster for each subset. According to [this](http://stackoverflow.com/questions/20364939/community-detection-with-infomap-algorithm-producing-one-massive-module) stack-overflow question answer this is because

> When a network collapses into one major cluster, it is most often because of a very dense and random link structure ... In the code for directed networks implemented in iGraph, teleportation is encoded. If many nodes have no outlinks, the effect of teleportation can be significant because it randomly connect nodes. We have made new code available here: http://www.mapequation.org/code.html that can cluster network without encoding the random teleportation necessary to make the dynamics ergodic. For details, see this paper: http://pre.aps.org/abstract/PRE/v85/i5/e056107

What I'm hypothesizing is that the chord distance does such a good job seperating nodes, that the teleportation effect fuses the communities. But I should look at the structure generated by the distance matrix between trips. 

Will look at trolling for 2010 to check. This is because I know there are at least two large clusters (albacore and salmon), but there should be at least one smaller one of halibut.


```{r}
# load tickets
tickets <- readRDS("/Users/efuller/1/CNH/Analysis/Metiers/results/2014-11-19/define_metiers/filtered_ftl.RDS")
trl <- subset(tickets, grgroup=="TLS" & year==2010)
library(reshape2)
melt_trl <- melt(trl, id.vars = c("veid","ftid","modified","tdate","grid"), measure.vars = c("landed_wt"))
cast_trl <- dcast(melt_trl, ftid ~ modified, fun.aggregate = sum)
rownames(cast_trl) <- cast_trl$ftid
cast_trl$ftid <- NULL
# try a heatmap 
heatmap(as.matrix(cast_trl))
```

Looks like there are two groups here but should look to see if i can reduce some of the albacore and salmon trips out

```{r}
# try with vegan transformation
library(vegan)
chord_mat <- decostand(cast_trl, "norm")
heatmap(as.matrix(unique(chord_mat)))
```

Looks like there's lots of variablility in the chinook catches, tend to be more multi-species. Will try the regular heatmap

```{r}
image(as.matrix(chord_mat)) 
# sort by albacore value, then by CHNK
chord_mat <- chord_mat[order(chord_mat$ALBC, chord_mat$CHNK, chord_mat$COHO, chord_mat$PHLB),]
image(as.matrix(chord_mat)) 
# reorder by colsums
chord_mat <- chord_mat[,order(colSums(chord_mat),decreasing = T)]
```

Alright, convinced that there are two clusters here with the chord distance. Should try with a distance matrix. 

```{r}
# reduce the trips to take some albacore and chinook out

nrow(chord_mat) - (length(which(chord_mat$ALBC==1))+length(which(chord_mat$CHNK==1)))
# should make sure I have at least 1000 of each of these groups

chord_reduce <- chord_mat[-which(chord_mat$ALBC==1)[1:1334],]
length(which(chord_reduce$ALBC==1))

chord_reduce <- chord_reduce[-which(chord_mat$CHNK==1)[1:2660],]
length(which(chord_reduce$CHNK==1))

dist_trl <- vegdist(chord_reduce, "euclidean")
library(gplots)
heatmap.2(as.matrix(dist_trl),dendrogram="none")
```

Generating output for infoMap

```{r}
dist_trl <- as.matrix(vegdist(chord_mat, "euclidean"))

sim_trl <- max(dist_trl) - dist_trl 
# gah, was doing the distance matrix. need the similarity matrix. i'm an idiot
# no wonder there was only one cluste.r 
library(igraph)

g <- graph.adjacency(sim_trl, mode = "undirected",weighted = TRUE ,diag=F)
link_list <-as.data.frame(cbind(get.edgelist(g)))
levels(link_list[,1]) <- levels(link_list[,2])
link_list$int_source <- as.integer(link_list[,1])
link_list$int_target <- as.integer(link_list[,2])
link_list$weight <- E(g)$weight
link_list[,1] <- NULL
write.graph(g, file = "/Users/efuller/1/CNH/Analysis/Metiers/results/2014-11-20/link_list",format="pajek")
write.table(link_list, file="/Users/efuller/1/CNH/Analysis/Metiers/results/2014-11-20/link_list.txt",sep="\t",quote=FALSE,row.names=FALSE, col.names=FALSE)
```

Even running infomap with the new code, get a solution with 5 nodes. Let's look at them.

```{r}
clusters <- read.table("/Users/efuller/1/CNH/Analysis/Metiers/results/2014-11-20/link_list.clu",skip=1)
table(clusters)

clusdf <- cbind(unique(link_list[,1]),clusters)
names(clusdf) <- c("ftid","cluster")

new_df <- cbind(cast_trl,rownames(cast_trl))
names(new_df)[ncol(new_df)] <- "ftid"
clusdf <- merge(clusdf, new_df, by="ftid")

library(plyr)

melt_catches <- melt(clusdf, id.vars = c("cluster","ftid"))
catches <- ddply(melt_catches, .(cluster,variable),summarize, mc = mean(value) )

library(ggplot2)
ggplot(subset(catches, mc>.1), aes(x = variable, y = mc)) + geom_bar(stat="identity") + facet_wrap(~cluster,scales = "free")

# try chord transformed
clusdf <- cbind(unique(link_list[,1]),clusters)
names(clusdf) <- c("ftid","cluster")

new_df <- cbind(chord_mat,rownames(chord_mat))
names(new_df)[ncol(new_df)] <- "ftid"
clusdf <- merge(clusdf, new_df, by="ftid")

melt_catches <- melt(clusdf, id.vars = c("cluster","ftid"))
catches <- ddply(melt_catches, .(cluster,variable),summarize, mc = mean(value) )

ggplot(subset(catches, mc>.1), aes(x = variable, y = mc)) + geom_bar(stat="identity") + facet_wrap(~cluster,scales = "free")

# this implicitly drops the one trip that had a totally different trip than everyone else.  I think that's ok. Still a little mystified why the mean amounts versus the proportional amounts are so different. Only explanation is that the chinook trips catch so much more than albacre for cluster 1.. but it appeared there were a lot of albacore only trips. 
```

There's something weird going on with the albacore and chinook trips. There are relatively few of those trips that catch both (8?) yet I'm seeing the chinook cluster (1) with trips that have only albacore. Am going to try the hellinger distance

```{r}
dist_hellinger <- as.matrix(vegdist(decostand(cast_trl, "hellinger"),"euclidean"))
sim_hellinger <- max(dist_hellinger)-dist_hellinger
g_hel <- graph.adjacency(sim_hellinger, mode = "undirected",weighted = TRUE)
link_list <-as.data.frame(cbind(get.edgelist(g_hel)))


levels(link_list[,1]) <- levels(link_list[,2])
link_list$int_source <- as.integer(link_list[,1])
link_list$int_target <- as.integer(link_list[,2])
link_list$weight <- E(g_hel)$weight
link_list[,1] <- NULL

write.table(link_list, file="/Users/efuller/1/CNH/Analysis/Metiers/results/2014-11-20/link_list_hel.txt",sep="\t",quote=FALSE,row.names=FALSE, col.names=FALSE)
```

```{r}
clusters <- read.table("/Users/efuller/1/CNH/Analysis/Metiers/results/2014-11-20/link_list_hel.clu",skip=1)

table(clusters)

link_list <-as.data.frame(cbind(get.edgelist(g_hel)))

clusdf <- cbind(unique(link_list[,1]),clusters)
names(clusdf) <- c("ftid","cluster")

new_df <- cbind(cast_trl,rownames(cast_trl))
names(new_df)[ncol(new_df)] <- "ftid"
clusdf <- merge(clusdf, new_df, by="ftid")

library(plyr)

melt_catches <- melt(clusdf, id.vars = c("cluster","ftid"))
catches <- ddply(melt_catches, .(cluster,variable),summarize, mc = mean(value) )

library(ggplot2)
ggplot(subset(catches, mc>.1), aes(x = variable, y = mc)) + geom_bar(stat="identity") + facet_wrap(~cluster,scales = "free")

```

This looks much better. Will go with hellinger to get clusters. 

Could I build a graph by year

```{r}
all_10 <- subset(tickets, year==2010)
melt_10 <- melt(all_10, id.vars = c("veid","ftid","modified","tdate","grid"), measure.vars = c("landed_wt"))
cast_10 <- dcast(melt_10, ftid ~ modified, fun.aggregate = sum)
rownames(cast_10) <- cast_10$ftid
cast_10$ftid <- NULL

ten_dist <- as.matrix(vegdist(decostand(cast_10,"hellinger"),"euclidean")) # too big. bummer. so have to still split by grgroups. 
```